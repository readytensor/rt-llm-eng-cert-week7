# ==============================================
# Model Configuration
# ==============================================
base_model: meta-llama/Llama-3.2-1B-Instruct
tokenizer_type: meta-llama/Llama-3.2-1B-Instruct

# ==============================================
# Dataset
# ==============================================
dataset:
  name: knkarthick/samsum
  cache_dir: ../data/datasets
  field_map:
    input: dialogue
    output: summary
  type: completion
  splits:
    train: all
    validation: 200
    test: 200
  seed: 42

# This is for Axolotl
datasets:
  - path: knkarthick/samsum
    cache_dir: ../data/datasets
    field_map:
      input: dialogue
      output: summary
    type: completion

task_instruction: >
  You are a helpful assistant who writes concise, factual summaries of conversations.
  Summarize the following conversation into a single sentence.

train_samples: all
val_samples: 200
test_samples: 200
seed: 42

# ==============================================
# Quantization (for QLoRA)
# ==============================================
load_in_4bit: true
bnb_4bit_quant_type: nf4
bnb_4bit_use_double_quant: true
bnb_4bit_compute_dtype: bfloat16

# ==============================================
# LoRA Configuration
# ==============================================
lora_r: 16
lora_alpha: 32
lora_dropout: 0.1
target_modules: ["q_proj", "v_proj"]

# ==============================================
# Training Configuration
# ==============================================
num_epochs: 1
max_steps: 300
learning_rate: 2e-4
batch_size: 4
gradient_accumulation_steps: 4
sequence_len: 512
lr_scheduler: cosine
warmup_steps: 50
bf16: true
logging_steps: 25
save_steps: 100
save_total_limit: 2
optim: paged_adamw_8bit

# ==============================================
# Output & Logging
# ==============================================
output_dir: ./outputs/lora_samsum
wandb_project: llama3_samsum
wandb_run_name: lora-finetuning-default-hps